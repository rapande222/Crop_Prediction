# -*- coding: utf-8 -*-
"""Crop_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iXPX-4vB1DYatoFDrF5eYRA1t5dBZ59T

This assignment involves building two deep learning models (CNN + Pre-trained Inception Model) to classify five types of crops (wheat, rice, sugarcane, maize, and jute) using 999 training images and 45 test images.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/Crop_details.csv')
df.head()

df.shape

df.info()

df.describe()

crop_counts = df['crop'].value_counts()
crop_counts

plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='crop', palette='viridis')
plt.title('Distribution of Crop Images', fontsize=16, fontweight='bold')
plt.xlabel('Crop Type', fontsize=12)
plt.ylabel('Number of Images', fontsize=12)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

df = df.drop('Unnamed: 0', axis=1)

sorted(df['croplabel'].unique())

crop_label = df[['crop','croplabel']].drop_duplicates().sort_values('croplabel')
crop_label_map = dict(zip(crop_label['crop'], crop_label['croplabel']))
crop_label_map

class_distribution = df.groupby(['crop', 'croplabel']).size().reset_index(name='count')
print(class_distribution.to_string(index=False))

import os
from google.colab import files
import zipfile


zip_filename = '/content/Archive.zip'

with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall('/content/')

df['path'] = df['path'].apply(lambda x: x.split('kag2/')[-1])

base_path = '/content/kag2/'
df['full_path'] = base_path + df['path']

df = df[df['full_path'].apply(os.path.exists)].reset_index(drop=True)

print(f"Total images to use: {len(df)}")
print(f"Images per class:\n{df['crop'].value_counts()}")

df.head()

import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img, img_to_array

img_height = 299
img_width = 299

def load_and_preprocess_image(image_path):
    img = load_img(image_path, target_size=(img_height, img_width))
    img_array = img_to_array(img)
    img_array = tf.keras.applications.inception_v3.preprocess_input(img_array)
    return img_array

import os
sample_path = df['full_path'].iloc[0]
print(sample_path)
print(os.path.dirname(sample_path))
print(os.listdir('/content'))

X_train = np.array([load_and_preprocess_image(path) for path in df['full_path']])
y_train = df['croplabel'].values

"""Implementing Pre-trained InceptionV3 model"""

from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

num_classes = len(np.unique(y_train))

base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))

for layer in base_model.layers[:-40]:
    layer.trainable = False
for layer in base_model.layers[-40:]:
    layer.trainable = True

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.4)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.3)(x)
output = Dense(num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

model.compile(
    optimizer=Adam(learning_rate=0.00015),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

#early_stop = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)

model.fit(X_train, y_train,epochs=20,batch_size=32,verbose=1)

test_folder_path = '/content/test_crop_image/'

def predict_images_IV3(folder_path):
    results = []
    for filename in os.listdir(folder_path):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            img_path = os.path.join(folder_path, filename)

            img = load_img(img_path, target_size=(299, 299))
            img_array = img_to_array(img)
            img_array = tf.keras.applications.inception_v3.preprocess_input(img_array)
            img_array = np.expand_dims(img_array, axis=0)

            pred = model.predict(img_array, verbose=0)
            pred_class = np.argmax(pred[0])
            confidence = pred[0][pred_class]

            results.append((filename, pred_class, confidence))
    return results

predictions = predict_images_IV3(test_folder_path)

if os.path.exists(test_folder_path):
    predictions = predict_images_IV3(test_folder_path)
else:
    print("Folder not found!")

label_to_name = {v: k for k, v in crop_label_map.items()}

correct = 0
total = 0

for filename, pred_class, confidence in predictions:
    crop_word = None
    for crop in crop_label_map.keys():
        if crop in filename.lower():
            crop_word = crop
            break

    predicted = label_to_name[int(pred_class)]

    if crop_word == predicted:
        correct += 1
    total += 1

    print(f"img={crop_word}, pred={predicted}, class={pred_class}, conf={confidence:.2%}")

accuracy = (correct / total) * 100
print(f"\nAccuracy: {correct}/{total} = {accuracy:.2f}%")

"""Inception V3 Model: The model was configured with all InceptionV3 layers frozen, trained for 10 epochs with a batch size of 32, achieving only 46.67% accuracy (21/45 correct predictions). To improve performance, several optimizations were applied: unfreezing the last 30-40 layers for fine-tuning, adding dense layers (256-512 neurons) with dropout regularization (0.3-0.5), reducing the learning rate to 0.0001-0.00015 for stable convergence, increasing training to 20-25 epochs, and using a smaller batch size of 16. The first improvement attempt with last 30 layers fine-tuned achieved 57.78% accuracy (26/45). However, aggressive fine-tuning by unfreezing all layers with higher learning rate (0.0003) resulted in overfitting, dropping accuracy to 53.33% (24/45), demonstrating that excessive fine-tuning can harm performance on small datasets. After balancing the approach with moderate fine-tuning (40 layers) and carefully tuned hyperparameters, the final model achieved 57.78% accuracy (26/45 correct predictions), representing an 11% improvement over the baseline. The key insight was that fine-tuning the deeper layers of the pre-trained model while maintaining appropriate regularization was crucial for adapting ImageNet-trained features to agricultural crop images.

Implementing CNN model
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
import numpy as np

model_cnn = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(299, 299, 3)),
    MaxPooling2D((2, 2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

model_cnn.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model_cnn.fit(X_train, y_train, epochs=20,batch_size=32,verbose=1)

test_folder_path = '/content/test_crop_image/'

def predict_images_cnn(folder_path):
    results = []
    for filename in os.listdir(folder_path):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            img_path = os.path.join(folder_path, filename)

            img = load_img(img_path, target_size=(299, 299))
            img_array = img_to_array(img)
            img_array = img_array / 255.0
            img_array = np.expand_dims(img_array, axis=0)

            pred = model_cnn.predict(img_array, verbose=0)
            pred_class = np.argmax(pred[0])
            confidence = pred[0][pred_class]

            results.append((filename, pred_class, confidence))
    return results

predictions_cnn = predict_images_cnn(test_folder_path)

label_to_name = {v: k for k, v in crop_label_map.items()}

correct_cnn = 0
total_cnn = 0

for filename, pred_class, confidence in predictions_cnn:
    crop_word = None
    for crop in crop_label_map.keys():
        if crop in filename.lower():
            crop_word = crop
            break

    predicted = label_to_name[int(pred_class)]

    if crop_word == predicted:
        correct_cnn += 1
    total_cnn += 1

    print(f"img={crop_word}, pred={predicted}, class={pred_class}, conf={confidence:.2%}")

accuracy_cnn = (correct_cnn / total_cnn) * 100
print(f"\nCNN Accuracy: {correct_cnn}/{total_cnn} = {accuracy_cnn:.2f}%")

"""CNN Model: The first approach was building a CNN from scratch with three convolutional layers having 32, 64, and 128 filters, followed by max pooling layers to reduce image dimensions. After flattening, a dense layer with 256 neurons and 0.5 dropout was added to prevent overfitting. The model used basic normalization (dividing pixel values by 255), Adam optimizer with 0.001 learning rate, and was trained for 30 epochs with batch size 32. This model achieved 28.89% accuracy (13 out of 45 correct predictions). The low accuracy shows that building a CNN from scratch requires a large amount of training data, which we didn't have.

Conclusion: This project shows that using pre-trained models is a practical approach for image classification tasks when you don't have large datasets. Fine-tuning needs to be done carefully unfreezing too many layers or using high learning rates can cause overfitting. The best results came from unfreezing a moderate number of layers (30-40) with proper regularization and a low learning rate. Overall, transfer learning proved to be much more effective than building a model from scratch for this agricultural crop classification problem.
"""

